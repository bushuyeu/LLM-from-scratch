{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ijR6qPINU_P6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ece405-assignment1-basics'...\n",
      "remote: Enumerating objects: 512, done.\u001b[K\n",
      "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 512 (delta 110), reused 108 (delta 103), pack-reused 384 (from 1)\u001b[K\n",
      "Receiving objects: 100% (512/512), 22.49 MiB | 16.30 MiB/s, done.\n",
      "Resolving deltas: 100% (273/273), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/bushuyeu/ece405-assignment1-basics.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "S5eKjGhFMiZ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/ece405-assignment1-basics\n"
     ]
    }
   ],
   "source": [
    "%cd ece405-assignment1-basics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uVh85UKdMng8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MLdwVyZ3MKk8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already on 'main'\n",
      "Your branch is up to date with 'origin/main'.\n"
     ]
    }
   ],
   "source": [
    "!git checkout main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUpCszLnfDf1"
   },
   "source": [
    "No need for Conda environment on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "D1tPK7iKenBW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///content/ece405-assignment1-basics\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: einops>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (0.8.2)\n",
      "Collecting einx>=0.3.0 (from cs336-basics==1.0.6)\n",
      "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting jaxtyping>=0.3.0 (from cs336-basics==1.0.6)\n",
      "  Downloading jaxtyping-0.3.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (2.0.2)\n",
      "Collecting psutil>=6.1.1 (from cs336-basics==1.0.6)\n",
      "  Downloading psutil-7.2.2-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: pytest>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (8.4.2)\n",
      "Requirement already satisfied: regex>=2024.11.6 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (2025.11.3)\n",
      "Collecting submitit>=1.5.2 (from cs336-basics==1.0.6)\n",
      "  Downloading submitit-1.5.4-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: tiktoken>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (0.12.0)\n",
      "Collecting torch~=2.6.0 (from cs336-basics==1.0.6)\n",
      "  Downloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (4.67.2)\n",
      "Requirement already satisfied: wandb>=0.19.7 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (0.24.1)\n",
      "Collecting ty>=0.0.1a16 (from cs336-basics==1.0.6)\n",
      "  Downloading ty-0.0.15-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "\u001b[33mWARNING: cs336-basics 1.0.6 does not provide the extra 'test'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from einx>=0.3.0->cs336-basics==1.0.6) (1.14.0)\n",
      "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx>=0.3.0->cs336-basics==1.0.6) (2.4.7)\n",
      "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.3.0->cs336-basics==1.0.6)\n",
      "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.4->cs336-basics==1.0.6) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.4->cs336-basics==1.0.6) (26.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.4->cs336-basics==1.0.6) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.4->cs336-basics==1.0.6) (2.19.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from submitit>=1.5.2->cs336-basics==1.0.6) (3.1.2)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.12/dist-packages (from submitit>=1.5.2->cs336-basics==1.0.6) (4.15.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.9.0->cs336-basics==1.0.6) (2.32.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (3.20.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Downloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (75.2.0)\n",
      "Collecting sympy (from einx>=0.3.0->cs336-basics==1.0.6)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->einx>=0.3.0->cs336-basics==1.0.6) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (3.1.46)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (2.12.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (6.0.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (2.51.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.19.7->cs336-basics==1.0.6) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.19.7->cs336-basics==1.0.6) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.19.7->cs336-basics==1.0.6) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.19.7->cs336-basics==1.0.6) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.9.0->cs336-basics==1.0.6) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.9.0->cs336-basics==1.0.6) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.9.0->cs336-basics==1.0.6) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.9.0->cs336-basics==1.0.6) (2026.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch~=2.6.0->cs336-basics==1.0.6) (3.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.19.7->cs336-basics==1.0.6) (5.0.2)\n",
      "Downloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jaxtyping-0.3.7-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psutil-7.2.2-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (155 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading submitit-1.5.4-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl (766.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.6/766.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ty-0.0.15-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
      "Building wheels for collected packages: cs336-basics\n",
      "  Building editable for cs336-basics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cs336-basics: filename=cs336_basics-1.0.6-py3-none-any.whl size=3234 sha256=b18d060760a0edb776e46debc7cf78a1e33ad6dcdfeecf431a45556c4636ac03\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-i8wb9x81/wheels/9c/8e/ad/47aa51c5b697fa6e79290e71856f3cf535f60484b164938fb6\n",
      "Successfully built cs336-basics\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, wadler-lindig, ty, sympy, submitit, psutil, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, einx, nvidia-cusolver-cu12, torch, cs336-basics\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.5.0\n",
      "    Uninstalling triton-3.5.0:\n",
      "      Successfully uninstalled triton-3.5.0\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.5\n",
      "    Uninstalling psutil-5.9.5:\n",
      "      Successfully uninstalled psutil-5.9.5\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
      "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.9.0+cu126\n",
      "    Uninstalling torch-2.9.0+cu126:\n",
      "      Successfully uninstalled torch-2.9.0+cu126\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.6.0 which is incompatible.\n",
      "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cs336-basics-1.0.6 einx-0.3.0 jaxtyping-0.3.7 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 psutil-7.2.2 submitit-1.5.4 sympy-1.13.1 torch-2.6.0 triton-3.2.0 ty-0.0.15 wadler-lindig-0.1.7\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "5abbbe5335d24bc09ace1fa5ffb81172",
       "pip_warning": {
        "packages": [
         "psutil"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -e .'[test]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "J-_dABLeW3LR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /content/ece405-assignment1-basics\n",
      "configfile: pytest.ini\n",
      "plugins: jaxtyping-0.3.7, anyio-4.12.1, typeguard-4.4.4, langsmith-0.6.8\n",
      "collected 3 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_train_bpe.py::test_train_bpe_speed \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 33%]\u001b[0m\n",
      "tests/test_train_bpe.py::test_train_bpe \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 66%]\u001b[0m\n",
      "tests/test_train_bpe.py::test_train_bpe_special_tokens \u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 1.06s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests/test_train_bpe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "id": "5wrA646Gf3Ht"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "/content/data\n",
      "owt_train.txt.gz    100%[===================>]   4.28G   104MB/s    in 55s     \n",
      "owt_valid.txt.gz    100%[===================>] 106.61M  60.5MB/s    in 1.8s    \n",
      "\n",
      "=== Download verification ===\n",
      "owt_train.txt: 11.92 GB\n",
      "owt_valid.txt: 0.29 GB\n",
      "/content/ece405-assignment1-basics\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "\n",
    "# Remove old data folder and start fresh\n",
    "!rm -rf data\n",
    "!mkdir -p data\n",
    "%cd data\n",
    "\n",
    "# Download TinyStories\n",
    "#!wget -q --show-progress https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/#TinyStoriesV2-GPT4-train.txt\n",
    "#!wget -q --show-progress https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-valid.txt\n",
    "\n",
    "# Download OpenWebText sample\n",
    "!wget -q --show-progress https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_train.txt.gz\n",
    "!gunzip owt_train.txt.gz\n",
    "!wget -q --show-progress https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_valid.txt.gz\n",
    "!gunzip owt_valid.txt.gz\n",
    "\n",
    "# Verify all downloads\n",
    "import os\n",
    "print(\"\\n=== Download verification ===\")\n",
    "for f in [\n",
    "    #\"TinyStoriesV2-GPT4-train.txt\", \n",
    "    # \"TinyStoriesV2-GPT4-valid.txt\", \n",
    "    \"owt_train.txt\", \n",
    "    \"owt_valid.txt\"\n",
    "    ]:\n",
    "    if os.path.exists(f):\n",
    "        size = os.path.getsize(f)\n",
    "        print(f\"{f}: {size / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(f\"{f}: MISSING!\")\n",
    "\n",
    "%cd /content/ece405-assignment1-basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "imports_and_helpers"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and helpers loaded.\n"
     ]
    }
   ],
   "source": [
    "# Imports and helper functions\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import tracemalloc\n",
    "from ece496b_basics import train_bpe\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "def safe_decode(b):\n",
    "    \"\"\"Safely decode bytes to string, falling back to repr if UTF-8 fails.\"\"\"\n",
    "    try:\n",
    "        return b.decode('utf-8')\n",
    "    except:\n",
    "        return repr(b)\n",
    "\n",
    "def analyze_vocab(vocab, name):\n",
    "    \"\"\"Print analysis of a vocabulary.\"\"\"\n",
    "    longest_token = max(vocab.values(), key=len)\n",
    "    avg_len = sum(len(v) for v in vocab.values()) / len(vocab)\n",
    "    \n",
    "    print(f\"\\n{name} Vocabulary Analysis:\")\n",
    "    print(f\"  Total tokens: {len(vocab)}\")\n",
    "    print(f\"  Merged tokens (non-byte): {len([k for k in vocab if k >= 256])}\")\n",
    "    print(f\"  Average token length: {avg_len:.2f} bytes\")\n",
    "    print(f\"  Longest token: '{safe_decode(longest_token)}' ({len(longest_token)} bytes)\")\n",
    "    \n",
    "    # Top 5 longest\n",
    "    print(f\"  Top 5 longest tokens:\")\n",
    "    for tid, tbytes in sorted(vocab.items(), key=lambda x: len(x[1]), reverse=True)[:5]:\n",
    "        print(f\"    ID {tid}: '{safe_decode(tbytes)}' ({len(tbytes)} bytes)\")\n",
    "\n",
    "print(\"Imports and helpers loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tinystories_header"
   },
   "source": [
    "## TinyStories BPE Training (vocab_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ts_training"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1029.17 seconds (17.15 minutes)\n",
      "Peak memory: 0.08 GB\n",
      "Number of merges: 9743\n",
      "\n",
      "TinyStories Vocabulary Analysis:\n",
      "  Total tokens: 10000\n",
      "  Merged tokens (non-byte): 9744\n",
      "  Average token length: 5.79 bytes\n",
      "  Longest token: ' accomplishment' (15 bytes)\n",
      "  Top 5 longest tokens:\n",
      "    ID 7159: ' accomplishment' (15 bytes)\n",
      "    ID 9142: ' disappointment' (15 bytes)\n",
      "    ID 9378: ' responsibility' (15 bytes)\n",
      "    ID 3227: ' uncomfortable' (14 bytes)\n",
      "    ID 3514: ' compassionate' (14 bytes)\n",
      "\n",
      "Saved to outputs/ts_vocab_10k.pkl and outputs/ts_merges_10k.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train BPE on TinyStories\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "ts_vocab, ts_merges = train_bpe(\n",
    "    input_path=\"/content/data/TinyStoriesV2-GPT4-train.txt\",\n",
    "    vocab_size=10000,\n",
    "    special_tokens=[\"<|endoftext|>\"]\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "_, peak_mem = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(f\"Training time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "print(f\"Peak memory: {peak_mem / 1e9:.2f} GB\")\n",
    "print(f\"Number of merges: {len(ts_merges)}\")\n",
    "\n",
    "analyze_vocab(ts_vocab, \"TinyStories\")\n",
    "\n",
    "# Save immediately\n",
    "with open(\"outputs/ts_vocab_10k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ts_vocab, f)\n",
    "with open(\"outputs/ts_merges_10k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ts_merges, f)\n",
    "print(\"\\nSaved to outputs/ts_vocab_10k.pkl and outputs/ts_merges_10k.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owt_header"
   },
   "source": [
    "## OpenWebText BPE Training (vocab_size=32000)\n",
    "\n",
    "**Problem (train_bpe_expts_owt)**: Train a byte-level BPE tokenizer on OpenWebText with vocab_size=32,000.\n",
    "\n",
    "Resource requirements: ≤12 hours (no GPUs), ≤100GB RAM\n",
    "\n",
    "**Note**: This will take several hours. Consider running overnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 28.3%\n",
      "RAM available: 39.2 GB\n"
     ]
    }
   ],
   "source": [
    "# Check current memory usage\n",
    "import psutil\n",
    "print(f\"RAM used: {psutil.virtual_memory().percent}%\")\n",
    "print(f\"RAM available: {psutil.virtual_memory().available / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "owt_training"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://8080-gpu-t4-hm-2rn4e5hihj8rt-c.asia-southeast1-1.prod.colab.dev/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "# Train BPE on OpenWebText with vocab_size=32000\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "owt_vocab, owt_merges = train_bpe(\n",
    "    input_path=\"/content/data/owt_train.txt\",\n",
    "    vocab_size=32000,\n",
    "    special_tokens=[\"<|endoftext|>\"]\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "_, peak_mem = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"OpenWebText BPE Training Complete!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes, {elapsed_time/3600:.2f} hours)\")\n",
    "print(f\"Peak memory: {peak_mem / 1e9:.2f} GB\")\n",
    "print(f\"Number of merges: {len(owt_merges)}\")\n",
    "\n",
    "analyze_vocab(owt_vocab, \"OpenWebText\")\n",
    "\n",
    "# Save immediately\n",
    "with open(\"outputs/owt_vocab_32k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(owt_vocab, f)\n",
    "with open(\"outputs/owt_merges_32k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(owt_merges, f)\n",
    "print(\"\\nSaved to outputs/owt_vocab_32k.pkl and outputs/owt_merges_32k.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison_header"
   },
   "source": [
    "## Compare TinyStories vs OpenWebText Tokenizers\n",
    "\n",
    "**Problem (train_bpe_expts_owt) Part (b)**: Compare and contrast the tokenizers trained on TinyStories vs OpenWebText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_load"
   },
   "outputs": [],
   "source": [
    "# Load vocabularies (in case running from fresh kernel after long OWT training)\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    ts_vocab\n",
    "    print(\"TinyStories vocab already in memory\")\n",
    "except NameError:\n",
    "    with open(\"outputs/ts_vocab_10k.pkl\", \"rb\") as f:\n",
    "        ts_vocab = pickle.load(f)\n",
    "    print(\"Loaded TinyStories vocab from disk\")\n",
    "\n",
    "try:\n",
    "    owt_vocab\n",
    "    print(\"OpenWebText vocab already in memory\")\n",
    "except NameError:\n",
    "    with open(\"outputs/owt_vocab_32k.pkl\", \"rb\") as f:\n",
    "        owt_vocab = pickle.load(f)\n",
    "    print(\"Loaded OpenWebText vocab from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_analysis"
   },
   "outputs": [],
   "source": [
    "# Compare token sets (excluding base 256 bytes)\n",
    "ts_tokens = set(v for k, v in ts_vocab.items() if k >= 256)\n",
    "owt_tokens = set(v for k, v in owt_vocab.items() if k >= 256)\n",
    "\n",
    "shared = ts_tokens & owt_tokens\n",
    "ts_only = ts_tokens - owt_tokens\n",
    "owt_only = owt_tokens - ts_tokens\n",
    "\n",
    "print(f\"TinyStories merged tokens: {len(ts_tokens)}\")\n",
    "print(f\"OpenWebText merged tokens: {len(owt_tokens)}\")\n",
    "print(f\"\\nShared tokens: {len(shared)}\")\n",
    "print(f\"  ({len(shared)/len(ts_tokens)*100:.1f}% of TinyStories tokens are in OWT)\")\n",
    "print(f\"  ({len(shared)/len(owt_tokens)*100:.1f}% of OWT tokens are in TinyStories)\")\n",
    "print(f\"\\nTokens unique to TinyStories: {len(ts_only)}\")\n",
    "print(f\"Tokens unique to OpenWebText: {len(owt_only)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_examples"
   },
   "outputs": [],
   "source": [
    "# Helper function (in case cell-8 wasn't run)\n",
    "def safe_decode(b):\n",
    "    try:\n",
    "        return b.decode('utf-8')\n",
    "    except:\n",
    "        return repr(b)\n",
    "\n",
    "# Show example tokens unique to each dataset (sorted by length for interesting examples)\n",
    "print(\"Top 15 longest tokens UNIQUE to TinyStories (children's stories):\")\n",
    "for t in sorted(ts_only, key=len, reverse=True)[:15]:\n",
    "    print(f\"  '{safe_decode(t)}'\")\n",
    "\n",
    "print(f\"\\nTop 15 longest tokens UNIQUE to OpenWebText (web text):\")\n",
    "for t in sorted(owt_only, key=len, reverse=True)[:15]:\n",
    "    print(f\"  '{safe_decode(t)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_stats"
   },
   "outputs": [],
   "source": [
    "# Compare statistics\n",
    "ts_longest = max(ts_vocab.values(), key=len)\n",
    "owt_longest = max(owt_vocab.values(), key=len)\n",
    "ts_avg_len = sum(len(v) for v in ts_vocab.values()) / len(ts_vocab)\n",
    "owt_avg_len = sum(len(v) for v in owt_vocab.values()) / len(owt_vocab)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Summary Statistics\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Metric':<30} {'TinyStories':>12} {'OpenWebText':>12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Vocab size':<30} {len(ts_vocab):>12} {len(owt_vocab):>12}\")\n",
    "print(f\"{'Avg token length (bytes)':<30} {ts_avg_len:>12.2f} {owt_avg_len:>12.2f}\")\n",
    "print(f\"{'Longest token (bytes)':<30} {len(ts_longest):>12} {len(owt_longest):>12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"TinyStories longest: '{safe_decode(ts_longest)}'\")\n",
    "print(f\"OpenWebText longest: '{safe_decode(owt_longest)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest OpenWebText Token (Helper)\n",
    "\n",
    "Run this cell to report the longest token in the trained OpenWebText vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the longest token in OpenWebText vocabulary\n",
    "import pickle\n",
    "try:\n",
    "    owt_vocab\n",
    "except NameError:\n",
    "    with open(\"outputs/owt_vocab_32k.pkl\", \"rb\") as f:\n",
    "        owt_vocab = pickle.load(f)\n",
    "# Re-define safe_decode if this is a fresh kernel\n",
    "def safe_decode(b):\n",
    "    try:\n",
    "        return b.decode(\"utf-8\")\n",
    "    except Exception:\n",
    "        return repr(b)\n",
    "longest_id, longest_token = max(owt_vocab.items(), key=lambda x: len(x[1]))\n",
    "print(f\"Longest token ID: {longest_id}\")\n",
    "print(f\"Longest token length: {len(longest_token)} bytes\")\n",
    "print(f\"Longest token (safe decode): {safe_decode(longest_token)}\")\n",
    "print(f\"Longest token (raw bytes): {repr(longest_token)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answers_header"
   },
   "source": [
    "## Answers to Assignment Questions\n",
    "\n",
    "### Part (a): What is the longest token in the OWT vocabulary? Does it make sense?\n",
    "\n",
    "*Fill in your answer here after running the cells above.*\n",
    "\n",
    "### Part (b): Compare and contrast TinyStories vs OpenWebText tokenizers.\n",
    "\n",
    "**Important**: Note that this comparison uses different vocab sizes (TinyStories: 10k, OWT: 32k) as specified by the assignment. When writing your answer, acknowledge this limitation and focus on qualitative differences (token types, domain-specific vocabulary) rather than raw token counts.\n",
    "\n",
    "*Fill in your answer here. Consider:*\n",
    "- *The vocab size difference (10k vs 32k) means OWT naturally has more tokens*\n",
    "- *What % of TinyStories tokens also appear in OWT? What does this suggest?*\n",
    "- *Types of tokens unique to each (children's vocabulary vs web/technical terms)*\n",
    "- *Average token length differences and what they indicate about text complexity*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "profiling_header"
   },
   "source": [
    "## Optional: Profiling (TinyStories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "profiling"
   },
   "outputs": [],
   "source": [
    "# Profile the training to see what takes the most time\n",
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "vocab_prof, merges_prof = train_bpe(\n",
    "    input_path=\"/content/data/TinyStoriesV2-GPT4-train.txt\",\n",
    "    vocab_size=10000,\n",
    "    special_tokens=[\"<|endoftext|>\"]\n",
    ")\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "s = StringIO()\n",
    "ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n",
    "ps.print_stats(20)\n",
    "print(s.getvalue())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
