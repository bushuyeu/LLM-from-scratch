{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Section 7: Experiment Analysis\n", "\n", "This notebook pulls training results from W&B and generates plots/tables for the writeup."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": ["import wandb\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "\n", "api = wandb.Api()\n", "PROJECT = \"ece496b-lm\"\n", "\n", "plt.rcParams.update({\"figure.figsize\": (10, 6), \"font.size\": 12})"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 7.2a Learning Rate Sweep\n", "Plot training and validation loss curves for each learning rate."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": ["# Fetch all LR sweep runs\n", "runs = api.runs(PROJECT, filters={\"display_name\": {\"$regex\": \"ts-lr-\"}})\n", "\n", "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n", "\n", "for run in sorted(runs, key=lambda r: r.config.get(\"max_learning_rate\", 0)):\n", "    lr = run.config.get(\"max_learning_rate\", \"?\")\n", "    history = run.history(keys=[\"train/loss\", \"val/loss\"], samples=5000)\n", "    label = f\"lr={lr}\"\n", "\n", "    # Training loss\n", "    train = history.dropna(subset=[\"train/loss\"])\n", "    ax1.plot(train[\"_step\"], train[\"train/loss\"], label=label, alpha=0.8)\n", "\n", "    # Validation loss\n", "    val = history.dropna(subset=[\"val/loss\"])\n", "    if not val.empty:\n", "        ax2.plot(val[\"_step\"], val[\"val/loss\"], label=label, marker=\"o\", markersize=3)\n", "\n", "ax1.set_xlabel(\"Step\")\n", "ax1.set_ylabel(\"Training Loss\")\n", "ax1.set_title(\"Training Loss — LR Sweep\")\n", "ax1.legend()\n", "ax1.set_ylim(0, 12)\n", "ax1.grid(True, alpha=0.3)\n", "\n", "ax2.set_xlabel(\"Step\")\n", "ax2.set_ylabel(\"Validation Loss\")\n", "ax2.set_title(\"Validation Loss — LR Sweep\")\n", "ax2.legend()\n", "ax2.set_ylim(0, 12)\n", "ax2.grid(True, alpha=0.3)\n", "\n", "plt.tight_layout()\n", "plt.savefig(\"../outputs/lr_sweep.png\", dpi=150, bbox_inches=\"tight\")\n", "plt.show()"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": ["# Summary table: final val loss for each LR\n", "rows = []\n", "for run in sorted(runs, key=lambda r: r.config.get(\"max_learning_rate\", 0)):\n", "    lr = run.config.get(\"max_learning_rate\", \"?\")\n", "    val_history = run.history(keys=[\"val/loss\"], samples=5000).dropna(subset=[\"val/loss\"])\n", "    final_val = val_history[\"val/loss\"].iloc[-1] if not val_history.empty else float(\"nan\")\n", "    status = \"diverged\" if run.state == \"crashed\" or final_val > 10 else f\"{final_val:.4f}\"\n", "    rows.append({\"Learning Rate\": lr, \"Final Val Loss\": status, \"State\": run.state})\n", "\n", "df = pd.DataFrame(rows)\n", "print(df.to_markdown(index=False))"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 7.2b Edge of Stability\n", "Analysis of how divergence threshold relates to the best learning rate."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": ["# TODO: After sweep completes, identify:\n", "# - Best LR (lowest final val loss)\n", "# - Highest non-divergent LR\n", "# - First divergent LR\n", "# Analyze relationship between best LR and edge of stability"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Batch Size Experiment"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": ["# TODO: Fetch batch size sweep runs and plot loss curves\n", "# runs = api.runs(PROJECT, filters={\"display_name\": {\"$regex\": \"ts-bs-\"}})"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Text Generation\n", "Load best checkpoint and generate 256+ tokens."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": ["import sys\n", "sys.path.insert(0, \"..\")\n", "import pickle\n", "import torch\n", "from ece496b_basics import TransformerLM, Tokenizer, generate, load_checkpoint, AdamW\n", "\n", "# Load tokenizer\n", "with open(\"../outputs/ts_vocab_10k.pkl\", \"rb\") as f:\n", "    vocab = pickle.load(f)\n", "with open(\"../outputs/ts_merges_10k.pkl\", \"rb\") as f:\n", "    merges = pickle.load(f)\n", "tokenizer = Tokenizer(vocab=vocab, merges=merges, special_tokens=[\"<|endoftext|>\"])\n", "\n", "# Load model from best checkpoint\n", "# TODO: update path to best checkpoint\n", "CKPT_PATH = \"../checkpoints/lr-1e-3/ckpt_final.pt\"\n", "model = TransformerLM(\n", "    vocab_size=10_000, context_length=256, d_model=512,\n", "    num_layers=8, num_heads=8, d_ff=1088, rope_theta=10000.0,\n", ")\n", "optimizer = AdamW(model.parameters())\n", "load_checkpoint(CKPT_PATH, model, optimizer)\n", "model.eval()\n", "\n", "# Generate\n", "eos_id = tokenizer.encode(\"<|endoftext|>\", special_tokens=True)[0]\n", "prompt = \"Once upon a time\"\n", "prompt_ids = tokenizer.encode(prompt)\n", "gen_ids = generate(model, prompt_ids, max_tokens=256, temperature=0.8, top_p=0.9, eos_token_id=eos_id)\n", "print(tokenizer.decode(gen_ids))"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 7.3 Ablations\n", "Compare baseline vs ablation runs."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": ["# TODO: After ablation runs complete, fetch and plot\n", "# ablation_names = [\"baseline\", \"no-rmsnorm\", \"post-norm\", \"no-rope\", \"ffn-silu\"]\n", "# runs = api.runs(PROJECT, filters={\"display_name\": {\"$regex\": \"ts-ablation-\"}})"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 7.4 OWT Training"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": ["# TODO: Fetch OWT run and plot loss curves + generate text"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
